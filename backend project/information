Ingestion: User uploads PDF $\rightarrow$ Text is extracted $\rightarrow$ Split into small "chunks".Indexing: Chunks are converted to numbers (Vectors) using an Embedding Model $\rightarrow$ Stored in ChromaDB (your "search database").Retrieval: User asks a question $\rightarrow$ We search ChromaDB for the most similar chunks.Generation: We send the Question + Relevant Chunks to the LLM (OpenAI/Llama) to get the final answer.
